{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries DataBase Evaluation Project\n",
    "\n",
    "## I/ Objectifs du projet\n",
    "\n",
    "Ce projet consiste à évaluer differentes bases de données orientées séries temporelles sur des cas d'utilisation liés à la mobilité, à l'éolien et à la gestion des réseaux d'énergie.\n",
    "\n",
    "Dans ce projet nous avons évalué les parties principales suivantes: \n",
    "- le service de collecte de données en streaming, \n",
    "- la gestion de la qualité des données, \n",
    "- l'exploration et la visualisation des données,\n",
    "- l'application de module de traitement des données et de machine learning. \n",
    "\n",
    "L'objectif de ce projet a été la construction d'une chaîne complète pour la simulation les réseaux d'énergie et la gestion des données. En comparant les fonctions et les bases de données différentes, on a pu comparer des résultats sur des cas de tests et offrir la possibilité d'appliquer et d'accélérer des modules maching learning.<br>\n",
    "\n",
    "### Evaluations principales de la performance : \n",
    "- Quatres bases de données : MongoDB, KairosDB, InfluxDB et Warp10\n",
    "- Test avec trois jeux de données\n",
    "- Ingestion et validation des données en streaming\n",
    "- Requêtes des données pour l'exploration et la visualisation\n",
    "- Algorithmes d'analyse et de machine learning\n",
    "- Accéleration du traitement des données avec Dask et Spark\n",
    "\n",
    "#### Cinq mots clés : Séries temporelles - Streaming - Gestion des données - Database - Evaluation de la performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## II/ Présentation des Bases de données de type Time Series étudiées\n",
    "\n",
    "### A/ MongoDB\n",
    "\n",
    "MongoDB est un système de gestion de base de données orienté documents, répartissable sur un nombre quelconque d'ordinateurs et ne nécessitant pas de schéma prédéfini des données.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Document\n",
    "    - Systèmes distribués\n",
    "    - Gestion manuel du temps \n",
    "- Ecosystem : \n",
    "    - Driver : JavaScript, Python, Ruby, Php, Java, Scala, etc...\n",
    "    - Outils et cadres d'intégration : Hadoop, Spark, Wireshark, BI, etc...\n",
    "    - Outils de Visualisation : MongoDB Compass, MongoDB Charts, Grafana\n",
    "- Avantages\n",
    "    - Flexibilité : MongoDB est une base de données sans schéma, qui signifie que nous pouvons avoir tout type de données dans un document séparé. \n",
    "    - Systèmes distribués & Disponibilité : Nous pouvons stocker une grande quantité de données en la distribuant à plusieurs serveurs connectés à l'application. Aussi, MongoDB utilise la réplication pour rendre les données plus durables.\n",
    "    - Haute vitesse : MongoDB est une base de données orientée document. Il est facile d'accéder aux documents par indexation. Par conséquent, il fournit une réponse rapide aux requêtes.\n",
    "- Inconvénient\n",
    "    - Jointures non prises en charge\n",
    "    - Utilisation élevée de la mémoire : L'absense de metadata et jointure entraînent une augmentation de l'utilisation inutile de la mémoire.\n",
    "- Dificultés\n",
    "    - Gestion des timestamps\n",
    "\n",
    "#### 2) Notebook [TutoMongoDB](./mongodb.ipynb)\n",
    "\n",
    "### B/ KairosDB\n",
    "KairosDB est une base de données orientée séries temporelles distribuées rapide et fiable, principalement utilisée pour Cassandra comme stockage sous-jacent (HBase, H2 peut également être utilisé). Il est réécrit sur la base d'OpenTSDB. Cette recherche est un exemple d'utilisation de H2 pour le stockage de données.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal :  \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Métrique \n",
    "    - Gestion temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : java\n",
    "    - Outils et cadres d'intégration : Warp10\n",
    "    - Outils de Visualisation : web GUI\n",
    "- Avantages : \n",
    "    - Agrégateurs : Lors de la requête, utilisez l'agrégateurs pour traiter les points de données. L'agrégateur peut être facilement éditer et ajouter les fonctions désirées.\n",
    "    - Transfert compressé : KairosDB prend en charge la compression gzip des données.\n",
    "- Inconvénient\n",
    "    - Structure de données : Un timestamp correspond à une valeur.\n",
    "    - le REST API ne supporte que timestamp en millisecondes.\n",
    "    - L'absense de driver aux autres languages.\n",
    "- Dificultés\n",
    "    - Réorganisation de la structure des données\n",
    "    - Passer la dictionnaire de requête dans une terminal\n",
    "    - Absense d'ecosystème\n",
    "    \n",
    "#### 2) Notebook [TutoKairosDB](./kairosdb.ipynb)\n",
    "\n",
    "### C/ InfluxDB\n",
    "InfluxDB est une base open source orientée séries temporelles (TSDB) développée par InfluxData. Il est écrit en Go et optimisé pour un stockage et une récupération rapides des données de séries temporelles dans des domaines tels que la surveillance des opérations, les mesures d'application et les données des capteurs.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Métrique \n",
    "    - Gestion temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : Arduino, C#, Go, JavaScript, Java, Php, Python, etc..\n",
    "    - Outils et cadres d'intégration : Telegraf, Kapacitor, Spark\n",
    "    - Outils de Visualisation : Chronograf, Grafana\n",
    "- Avantages\n",
    "    - Politiques de rétention : il fournit une façon facile pour ajuster la rétention des données vers le haut ou vers le bas pour éviter les plantages catastrophiques sur le disque.\n",
    "- Inconvénient\n",
    "    - Line protocol : moins flexible pour la structure des données\n",
    "    - Stackage des fragments concernant la périodes de rétention : Lorsque les données sont supprimées en raison de l'expiration de la date de conservation, le fragment entier est perdu.\n",
    "- Dificultés\n",
    "    - Utilisaion des guillemets : difficile à écrire les requêtes et le passer dans une terminal\n",
    "\n",
    "#### 2) Notebook [TutoInfluxDB](./influxdb.ipynb)\n",
    "\n",
    "### D/ Warp10\n",
    "La plateforme Warp 10 est conçue pour simplifier la gestion et le traitement des données de séries temporelles. Il comprend une base de données Geo Time Series et un moteur d'analyse complémentaire.\n",
    "\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : GTS (Geo Time Series)\n",
    "    - Gestion du temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : Python\n",
    "    - Outils et cadres d'intégration : Hadoop, Spark, Pig, Zeppelin, VSCode, StatsD, CollectD, Telegraf, etc...\n",
    "    - Outils de Visualisation : Warp View\n",
    "- Avantages\n",
    "    - Gestion de GTS : pratique pour les données envoyées par capture\n",
    "    - Environnement d'analyse : langage de programmation de flux de données appelé WarpScript offert plus de 1000 functions disponibles\n",
    "- Inconvénient\n",
    "    - L'absense de tuto et doc\n",
    "- Dificultés\n",
    "    - Installation\n",
    "    - Configuration des plugins pour utiliser warp10 en python\n",
    "    - Difficle d'exécuter warpscript en python\n",
    "    - Préparation des donneés au format de GTS\n",
    "\n",
    "#### 2) Notebook [TutoWarp10](./warp10.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## III/ Présentation des jeux de données étudiés\n",
    "\n",
    "### A/ Données SmartGrid\n",
    "\n",
    "Données issues de la base de données hystorian\n",
    "\n",
    "Il s'agit des données transmises par des capteurs du bâtiment  Cryolite.\n",
    "\n",
    "Trois fichiers csv correspondant à :\n",
    "- Un jour de collecte\n",
    "- Une semaine de collecte\n",
    "- Un mois de collecte\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [SmartGridData](./smartgrid_data.ipynb)\n",
    "\n",
    "### B/ Données Eolienne\n",
    "\n",
    "Il s'agit de données collectées par des capteurs dans des éoliennes de la zone de Lacq.\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [WindPropData](./windprop_data.ipynb)\n",
    "\n",
    "### C/ Données de pollution\n",
    "\n",
    "Il s'agit de données collectées par des capteurs de pollution dans des véhicules lors d'expérimentation de controle de pollution sur des profils de trajet.\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [PolluantData](./polluant_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV/ Présentation de l' architecture du framework données\n",
    "<img src=\"img/schemaV2.PNG\" width=\"800\"/>\n",
    "\n",
    "## V/ Collecte & préparation des données\n",
    "\n",
    "La collecte des données en streaming est basée sur l'architectures suivantes :\n",
    "- des producteurs de données simulant capteurs produisent et écrivent des données sur le topic d'un serveur Kafka\n",
    "- des consommateurs de données collectent les données sur les topics, les valident, les corrigent puis les écrivent dans des base de données\n",
    "\n",
    "<img src=\"img/consumer-group-kafka.png\" width=\"800\"/>\n",
    "\n",
    "Le notebook [KafkaProducer](data_producer.ipynb) illustre les méchanismes de production de données et écriture sur des topics Kafka.\n",
    "\n",
    "Le notebook [KafkaConsumer](data_consumer.ipynb) illustre les méchanismes de consommation de données à partir de topics Kafka, puis la validation, la corrections puis la mise en bases.\n",
    "\n",
    "Tous ces mécanismes sont valider pour les 3 use cases:\n",
    "- Données SmartGrid\n",
    "- Données Eolienne\n",
    "- Données de polution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI/ Exploration des données et visualisation\n",
    "\n",
    "### A/ Outils de visualisation\n",
    "\n",
    "- Graphana\n",
    "- Outils spécifiques à chaque type de base\n",
    "- Visdom\n",
    "\n",
    "### B/ test de Visdom et Matplotlib\n",
    "\n",
    "Le notebook [DataExploration](./visualiser.html) illustre les mécanismes de requétage des données stokées en base et comment visualiser ces données avec matplotlib ou des outils comme visdom dans des navigateurs web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII/ Analyse de données et Machine learning\n",
    "\n",
    "Le notebook [MachineLearning](./data_analytics.html) illustre comment requéter des données pour appliquer des algorithmes d'analyse de données et de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII/ Performance\n",
    "\n",
    "### A/ Dashboard Jaeger\n",
    "<img src = \"img/p_kairosdb_wp.png\" width=\"800\"/>\n",
    "\n",
    "### B/ Analyse des performances des différentes bases en mode ingestion de données et requetes\n",
    "\n",
    "Dans le tableau suivant nous comparons pour les jeux de données SmartGrid (SG1M) et WindProp (WP25)\n",
    "- les temps d'insertion de données des jeux de données dans les 4 bases (insert)\n",
    "- les temps de requetes de tous le jeux de données (allquery)\n",
    "- les temps de requetes pour certains tags (select)\n",
    "\n",
    "Les tests sont executés à partir du cluster LAB\n",
    "Les bases sont situés sur le cluster Evoa\n",
    "#### Mode local\n",
    "1) Insert (en seconde)\n",
    "\n",
    "| BucketSize\\Database| MongoDB | KairosDB | InfluxDB | Warp10 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "| SG1M 1000 | 10.87 | 64.35 | 49.21 | 55.03 |\n",
    "| SG1M 2000 | 9.98 | 63.00 | 33.04 | 39.67 |\n",
    "| SG1M 4000 | 9.50 | 61.46 | 23.56 | 24.58 |\n",
    "| SG1M 8000 | 11.00 | 60.17 | 19.41 | 16.72 |\n",
    "| SG1M 16000 | 9.86 | 59.10 | 18.44 | 12.88 |\n",
    "| SG1M 32000 | 10.06  | 60.40 | 16.79 | 12.25 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "|WP25 100 | 0.49 | 0.92 | 2.30 | 736.31 |\n",
    "|WP25 200 | 0.43 | 1.46 | 1.58 | 373.40 |\n",
    "|WP25 400 | 0.47 | 0.72  | 0.89 | 192.18 |\n",
    "|WP25 800 | 0.51 | 0.71 | 0.60 | 101.31 |\n",
    "|WP25 1600 | 0.50 | 1.22 | 0.46 | 50.95 |\n",
    "|WP25 3200 | 0.56 | 0.67 | 0.42 | 30.70 |\n",
    "\n",
    "\n",
    "\n",
    "2) Allquery (en seconde)\n",
    "\n",
    "| BucketSize\\Database| MongoDB | KairosDB | InfluxDB | Warp10 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "| SG1M | 4.10 | 0.94 | 3.92 | 0.35 |\n",
    "| WP25 | 0.56 | 0.02 | 0.13 | 0.12 |\n",
    "\n",
    "\n",
    "#### Mode cluster-evoa\n",
    "\n",
    "1) Insert (en seconde)\n",
    "\n",
    "| BucketSize\\Database| MongoDB | KairosDB | InfluxDB | Warp10 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "| SG1M 1000 | 21.09 | 10.63 | 26.79 | 55.03 |\n",
    "| SG1M 2000 | 18.93 | 8.35 | 24.21 | 39.67 |\n",
    "| SG1M 4000 | 18.52 | 6.66 | 22.65 | 24.58 |\n",
    "| SG1M 8000 | 17.72 | 6.02 | 20.61 | 16.72 |\n",
    "| SG1M 16000 | 16.61 | 4.81 | 19.79 | 12.88 |\n",
    "| SG1M 32000 | 16.22  | 3.97 | 17.75 | 12.25 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "|WP25 100 | 0.76 | 0.95 | 0.79 | 2.98 |\n",
    "|WP25 200 | 0.72 | 0.38 | 0.84 | 1.37 |\n",
    "|WP25 400 | 0.65 | 0.23 | 0.43 | 0.99 |\n",
    "|WP25 800 | 0.68 | 0.19 | 0.31 | 0.84 |\n",
    "|WP25 1600 | 0.61 | 0.21 | 0.24 | 1.19 |\n",
    "|WP25 3200 | 0.65 | 0.15 | 0.30 | 0.67 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C/ Accéleration des traitements de données avec Spark\n",
    "\n",
    "Il s'agit d'accélérer le calcul de la courbe moyenne sur un jour des donnes collectés sur 1 mois de tous les capteurs du batiment Cryolite\n",
    "\n",
    "Dans le notebook [SparkAnalytics](./data_analytics_pyspark.ipynb) nous illustrons le calcul des ces courbes sur le clusteur LAB avec Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D/ Accéleration des traitements de données avec Dask\n",
    "\n",
    "Il s'agit d'accélérer le calcul de la courbe moyenne sur un jour des donnes collectés sur 1 mois de tous les capteurs du batiment Cryolite\n",
    "\n",
    "Dans le notebook [DaskAnalytics](./data_analytics_dask.ipynb) nous illustrons le calcul des ces courbes sur le clusteur LAB avec Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E/ Comparaison Pandas, Spark et Dask \n",
    "\n",
    "On mesure le temps pour créer les clients Dask ou Spark sur le cluster LAB, le temps du calcul avec des dataframe Pandas, PySpark ou Dask et les temps totaux des tests.\n",
    "\n",
    "| Test        | Pandas  | PySpark | Dask    |\n",
    "| ----------- | --------|---------|---------|\n",
    "| Client      | 0.      | 2.49    | 48.15   |\n",
    "| Analytics   | 18.5    | 8.43    | 9.84    |\n",
    "| Total       | 27.9    | 33.7    | 80.30   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IX/ Conclusion et perspectives\n",
    "\n",
    "- Terminer les tests sur le cluster LAB\n",
    "- Utilisation de nouveau cas d'utilisation métiers\n",
    "- Valider des requetes plus compliqués (timestamp, expression avec des tags)\n",
    "- Statistique directement avec fonction de requête évolué de la base de données\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
