{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TimeSeries DataBase Evaluation Project\n",
    "\n",
    "## I/ Objectifs du projet\n",
    "Ce projet consiste à évaluer sur des cas d'utilisation liés à la mobilité, à éolien et à la gestion des réseaux d'énergie. Il donc contient cinq parties principales : le service en streaming, la gestion de la qualité des données, l'évaluation de plusieurs types de base de données en concernant les opérations différentes, l'analyse et visualisation des données et l'application du module machine learning. L'objectif de ce projet est la construction d'une chaîne complète pour la simulation les réseaux d'énergie et la gestion des données. En comparant les fonctions et les bases de données différentes, on peut trouver le meilleur résultat sur des cas de tests et offrir la possibilité d'appliquer et d'accélérer des modules maching learning.<br>\n",
    "\n",
    "### Evaluations principales de la performance : \n",
    "- Quatres bases de données : MongoDB, KairosDB, InfluxDB et Warp10\n",
    "- Test avec trois jeux de données\n",
    "- Ingestion et validation des données en streaming\n",
    "- Requêtes des données pour l'exploration et la visualisation\n",
    "- Algorithmes d'analyse et de machine learning\n",
    "- Accéleration du traitement des données avec Dask et Spark\n",
    "\n",
    "#### Cinq mots clés : Séries temporelles - Streaming - Gestion des données - Database - Evaluation de la performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## II/ Présentation des Bases de données de type Time Series étudiées\n",
    "\n",
    "### A/ MongoDB\n",
    "\n",
    "MongoDB est un système de gestion de base de données orienté documents, répartissable sur un nombre quelconque d'ordinateurs et ne nécessitant pas de schéma prédéfini des données.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Document\n",
    "    - Systèmes distribués\n",
    "    - Gestion manuel du temps \n",
    "- Ecosystem : \n",
    "    - Driver : JavaScript, Python, Ruby, Php, Java, Scala, etc...\n",
    "    - Outils et cadres d'intégration : Hadoop, Spark, Wireshark, BI, etc...\n",
    "    - Outils de Visualisation : MongoDB Compass, MongoDB Charts, Grafana\n",
    "- Avantages\n",
    "    - Flexibilité : MongoDB est une base de données sans schéma, qui signifie que nous pouvons avoir tout type de données dans un document séparé. \n",
    "    - Systèmes distribués & Disponibilité : Nous pouvons stocker une grande quantité de données en la distribuant à plusieurs serveurs connectés à l'application. Aussi, MongoDB utilise la réplication pour rendre les données plus durables.\n",
    "    - Haute vitesse : MongoDB est une base de données orientée document. Il est facile d'accéder aux documents par indexation. Par conséquent, il fournit une réponse rapide aux requêtes.\n",
    "- Inconvénient\n",
    "    - Jointures non prises en charge\n",
    "    - Utilisation élevée de la mémoire : L'absense de metadata et jointure entraînent une augmentation de l'utilisation inutile de la mémoire.\n",
    "- Dificultés\n",
    "    - Gestion des timestamps\n",
    "\n",
    "#### 2) Notebook [TutoMongoDB](./mongodb.ipynb)\n",
    "\n",
    "### B/ KairosDB\n",
    "KairosDB est une base de données orientée séries temporelles distribuées rapide et fiable, principalement utilisée pour Cassandra comme stockage sous-jacent (HBase, H2 peut également être utilisé). Il est réécrit sur la base d'OpenTSDB. Cette recherche est un exemple d'utilisation de H2 pour le stockage de données.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal :  \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Métrique \n",
    "    - Gestion temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : java\n",
    "    - Outils et cadres d'intégration : Warp10\n",
    "    - Outils de Visualisation : web GUI\n",
    "- Avantages : \n",
    "    - Agrégateurs : Lors de la requête, utilisez l'agrégateurs pour traiter les points de données. L'agrégateur peut être facilement éditer et ajouter les fonctions désirées.\n",
    "    - Transfert compressé : KairosDB prend en charge la compression gzip des données.\n",
    "- Inconvénient\n",
    "    - Structure de données : Un timestamp correspond à une valeur.\n",
    "    - le REST API ne supporte que timestamp en millisecondes.\n",
    "    - L'absense de driver aux autres languages.\n",
    "- Dificultés\n",
    "    - Réorganisation de la structure des données\n",
    "    - Passer la dictionnaire de requête dans une terminal\n",
    "    - Absense d'ecosystème\n",
    "    \n",
    "#### 2) Notebook [TutoKairosDB](./kairosdb.ipynb)\n",
    "\n",
    "### C/ InfluxDB\n",
    "InfluxDB est une base open source orientée séries temporelles (TSDB) développée par InfluxData. Il est écrit en Go et optimisé pour un stockage et une récupération rapides des données de séries temporelles dans des domaines tels que la surveillance des opérations, les mesures d'application et les données des capteurs.\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : Métrique \n",
    "    - Gestion temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : Arduino, C#, Go, JavaScript, Java, Php, Python, etc..\n",
    "    - Outils et cadres d'intégration : Telegraf, Kapacitor, Spark\n",
    "    - Outils de Visualisation : Chronograf, Grafana\n",
    "- Avantages\n",
    "    - Politiques de rétention : il fournit une façon facile pour ajuster la rétention des données vers le haut ou vers le bas pour éviter les plantages catastrophiques sur le disque.\n",
    "- Inconvénient\n",
    "    - Line protocol : moins flexible pour la structure des données\n",
    "    - Stackage des fragments concernant la périodes de rétention : Lorsque les données sont supprimées en raison de l'expiration de la date de conservation, le fragment entier est perdu.\n",
    "- Dificultés\n",
    "    - Utilisaion des guillemets : difficile à écrire les requêtes et le passer dans une terminal\n",
    "\n",
    "#### 2) Notebook [TutoInfluxDB](./influxdb.ipynb)\n",
    "\n",
    "### D/ Warp10\n",
    "La plateforme Warp 10 est conçue pour simplifier la gestion et le traitement des données de séries temporelles. Il comprend une base de données Geo Time Series et un moteur d'analyse complémentaire.\n",
    "\n",
    "#### 1) Présentation\n",
    "- Caratéristiques principal : \n",
    "    - Base NoSQL\n",
    "    - Modèle de données : GTS (Geo Time Series)\n",
    "    - Gestion du temps dans la base\n",
    "- Ecosystem : \n",
    "    - Driver : Python\n",
    "    - Outils et cadres d'intégration : Hadoop, Spark, Pig, Zeppelin, VSCode, StatsD, CollectD, Telegraf, etc...\n",
    "    - Outils de Visualisation : Warp View\n",
    "- Avantages\n",
    "    - Gestion de GTS : pratique pour les données envoyées par capture\n",
    "    - Environnement d'analyse : langage de programmation de flux de données appelé WarpScript offert plus de 1000 functions disponibles\n",
    "- Inconvénient\n",
    "    - L'absense de tuto et doc\n",
    "- Dificultés\n",
    "    - Installation\n",
    "    - Configuration des plugins pour utiliser warp10 en python\n",
    "    - Difficle d'exécuter warpscript en python\n",
    "    - Préparation des donneés au format de GTS\n",
    "\n",
    "#### 2) Notebook [TutoWarp10](./warp10.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "## III/ Présentation des jeux de données étudiés\n",
    "\n",
    "### A/ Données SmartGrid\n",
    "\n",
    "Données issues de la base de données hystorian\n",
    "\n",
    "Il s'agit des données transmises par des capteurs du batiement Cryolite.\n",
    "\n",
    "Trois fichiers csv correspondant à :\n",
    "- Un jour de collecte\n",
    "- Une semaine de collecte\n",
    "- Un mois de collecte\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [SmartGridData](./smartgrid_data.ipynb)\n",
    "\n",
    "### B/ Données Eolienne\n",
    "\n",
    "Il s'agit de données collectées par des capteurs dans des éoliennes de la zone de Lacq.\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [WindPropData](./windprop_data.ipynb)\n",
    "\n",
    "### C/ Données de polution\n",
    "\n",
    "Il s'agit de données collectées par des capteurs de pollution dans des véhicules lors d'expérimentation de controle de pollution sur des profils de trajet.\n",
    "\n",
    "Une présentation plus détaillée des données se trouve dans le Notebook [PolluantData](./polluant_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV/ Présentation de l' architecture du framework données\n",
    "<img src=\"img/shema1.PNG\" width=\"800\"/>\n",
    "\n",
    "## V/ Collecte des données\n",
    "\n",
    "La collecte des données en streaming est basée sur l'architectures suivantes :\n",
    "- des producteurs de données simulant capteurs produisent et écrivent des données sur le topic d'un serveur Kafka\n",
    "- des consommateurs de données collectent les données sur les topics, les valident, les corrigent puis les écrivent dans des base de données\n",
    "\n",
    "<img src=\"img/consumer-group-kafka.png\" width=\"800\"/>\n",
    "\n",
    "Le notebook [KafkaProducer](data_producer.ipynb) illustre les méchanismes de production de données et écriture sur des topics Kafka.\n",
    "\n",
    "Le notebook [KafkaConsumer](data_consumer.ipynb) illustre les méchanismes de consommation de données à partir de topics Kafka, puis la validation, la corrections puis la mise en bases.\n",
    "\n",
    "Tous ces mécanismes sont valider pour les 3 use cases:\n",
    "- Données SmartGrid\n",
    "- Données Eolienne\n",
    "- Données de polution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI/ Exploration des données et visualisation\n",
    "\n",
    "### A/ Outils de visualisation\n",
    "\n",
    "- Graphana\n",
    "- Outils spécifiques à chaque type de base\n",
    "- Visdom\n",
    "\n",
    "### B/ test de Visdom et Matplotlib\n",
    "\n",
    "Le notebook [DataExploration](./visualiser.ipynb) illustre les mécanismes de requétage des données stokées en base et comment visualiser ces données avec matplotlib ou des outils comme wisdom dans des navigateurs web"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII/ Analyse de données et Machine learning\n",
    "\n",
    "Le notebook [MachineLearning](./data_analytics.ipynb) illustre comment requéter des données pour appliquer des algorithmes d'analyse de données et de machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII/ Performance\n",
    "\n",
    "| Test        | MongoDB     | KairosDB | InfluxDB | Warp10 |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "|SG1M insert  | 25.57       | 25.39    | 36.56    | 31.17  |\n",
    "|SG1M allquery| 4.12        | 0.85     | 3.85     | 0.30   |\n",
    "|SG1M allparse|             | 2.24     |          |        |\n",
    "|SG1M select  | 0.11        | 0.11     | 2.47     | 0.18   |\n",
    "|SG1M selparse|             |          | 1.21     |        |\n",
    "| ----------- | ----------- |----------|----------|--------|\n",
    "|WP25 insert  | 0.64        | 0.47     | 0.49     | 0.56   |\n",
    "|WP25 allquery| 0.1617      | 0.024    | 0.11     | 0.064  |\n",
    "|WP25 allparse| 0.13        | 0.00031  | 0.07     |        |\n",
    "| ----------- | ----------- |----------|----------|--------|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
