{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data producer NoteBook\n",
    "\n",
    "## I/ Objectifs\n",
    "\n",
    "L'objectif du notebook est d'illustrer comment connecter des producteurs de données à des Broker Kafka en streaming pour les 3 cas d'utilisations :\n",
    "- SmartGrid\n",
    "- Données éolienne\n",
    "- Données de pollution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir='/home/irsrvshare2/R11/dgt_sandb/data/TimeSeries'\n",
    "\n",
    "kafka_server = \"islin-hdplnod06:6667\"\n",
    "kafka_server = \"islin-hdpnod1:6667\"\n",
    "kafka_server=\"localhost:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from kafka import KafkaProducer\n",
    "import glob\n",
    "def readFiles(path):\n",
    "    all_files =  glob.glob(os.path.join(path,\"*.csv\"))\n",
    "    li = []\n",
    "    for filename in all_files:\n",
    "        print(filename)\n",
    "        df = pd.read_csv(filename, header=0, encoding='latin-1')\n",
    "        li.append(df)\n",
    "    frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "    return frame\n",
    "\n",
    "def readOneFile(filename):\n",
    "    print(filename)\n",
    "    df = pd.read_csv(filename, header=0, encoding='latin-1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II/ Données SmartGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smartgrid_data_producer(df,topic,broker_server):\n",
    "    producer = KafkaProducer(bootstrap_servers=broker_server)\n",
    "    while True:\n",
    "        for index,row in df.iterrows():\n",
    "            count=str(row.name)\n",
    "            msg= str(row[0])\n",
    "            for i in range(1,len(row)):\n",
    "                msg = msg + \";\"+ str(row[i])\n",
    "            #Configuration of broker:auto.create.topics.enable\n",
    "            msg=count+\":\"+msg\n",
    "            producer.send(topic,msg.encode('utf8'))\n",
    "            #print(\"{} Produced records[{}] : {}\".format(time.time(), index,msg))\n",
    "            time.sleep(0.1)\n",
    "        time.sleep(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name = 'SmartGridData/Cryolite/20190101'\n",
    "test_name = 'OneDay'\n",
    "path = os.path.join(data_dir,case_name,test_name)\n",
    "topic = 'SmartGridDataCryolite20190101'+test_name+'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readOneFile(path)\n",
    "smartgrid_data_producer(df,topic,kafka_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "766415:31/01/2019 09:05:38;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-2.000000000;100.0<br>\n",
    "766416:31/01/2019 09:05:59;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-1.000000000;100.0<br>\n",
    "766417:31/01/2019 09:06:05;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-2.000000000;100.0<br>\n",
    "766418:31/01/2019 09:06:09;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-1.000000000;100.0<br>\n",
    "766419:31/01/2019 09:06:30;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-2.000000000;100.0<br>\n",
    "766420:31/01/2019 09:06:34;CRY.TGBT_NORMAL.CRY_rea_cons_pow;-1.000000000;100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III/ Données Eolienne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windprop_data_producer(df,topic,broker_server):\n",
    "    producer = KafkaProducer(bootstrap_servers=broker_server)\n",
    "    while True:\n",
    "        for index,row in df.iterrows():\n",
    "            count=str(row.name)\n",
    "            msg= str(row[0])\n",
    "            for i in range(1,len(row)):\n",
    "                msg = msg + \";\"+ str(row[i])\n",
    "            #Configuration of broker:auto.create.topics.enable\n",
    "            msg=count+\":\"+msg\n",
    "            producer.send(topic,msg.encode('utf8'))\n",
    "            #print(\"{} Produced records[{}] : {}\".format(time.time(), index,msg))\n",
    "            time.sleep(0.1)\n",
    "        time.sleep(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name = 'WindPropData'\n",
    "test_name = 'Lacq_1day'\n",
    "path = os.path.join(data_dir,case_name,test_name)\n",
    "topic = casename+test_name+'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readFiles(path)\n",
    "windprop_data_producer(df,topic,kafka_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7285:02/10/2019 11:12:27;7285;1,010000;888888,00;9,00;17,00;0,20;1,009;29,558;43,247617;-0,384970;94,3000;73,300;1,017;17,000;79,500;270,40;4,20;272,50;4,30;0,0000;0,0000;0,0000;0,0000;0,000000;0,000000;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,000000;0,000000;148,00;45,00;2,01;2,05;-0,01;-0,01;0,02;1,69;392,95;-0,01;-48,51;-50,24;-48,48;-48,02<br>\n",
    "7286:02/10/2019 11:12:28;7286;1,010000;888888,00;9,00;17,00;0,20;1,009;29,547;43,247617;-0,384970;94,3000;73,300;1,017;17,000;79,500;270,40;4,20;272,50;4,30;0,0000;0,0000;0,0000;0,0000;0,000000;0,000000;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,000000;0,000000;148,00;45,00;2,01;2,05;-0,01;-0,01;0,02;1,69;392,95;-0,01;-48,51;-50,24;-48,48;-48,02<br>\n",
    "7287:02/10/2019 11:12:29;7287;1,010000;888888,00;9,00;17,00;0,20;1,009;29,537;43,247617;-0,384970;94,3000;73,300;1,017;17,000;79,500;270,40;4,20;272,50;4,30;0,0000;0,0000;0,0000;0,0000;0,000000;0,000000;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,00;0,000000;0,000000;148,00;45,00;2,01;2,05;-0,01;-0,01;0,02;1,69;392,66;-0,00;-52,53;-50,41;-48,54;-48,06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV/ Données de pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pollution_data_producer(df,topic,broker_server):\n",
    "    producer = KafkaProducer(bootstrap_servers=broker_server)\n",
    "    while True:\n",
    "        for index,row in df.iterrows():\n",
    "            count=str(row.name)\n",
    "            msg= str(row[0])\n",
    "            for i in range(1,len(row)):\n",
    "                msg = msg + \";\"+ str(row[i])\n",
    "            #Configuration of broker:auto.create.topics.enable\n",
    "            msg=count+\":\"+msg\n",
    "            producer.send(topic,msg.encode('utf8'))\n",
    "            #print(\"{} Produced records[{}] : {}\".format(time.time(), index,msg))\n",
    "            time.sleep(0.1)\n",
    "        time.sleep(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_name = 'PollutionData'\n",
    "test_name = 'Test1'\n",
    "path = os.path.join(data_dir,case_name,test_name)\n",
    "topic = casename+test_name+'Topic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = readFiles(path)\n",
    "pollution_data_producer(df,topic,kafka_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0:0;0;0;20.799999237060547;198;0;0;0;0;0;0;0;0;0;0;2019-09-24 08:12:05.357000;2019-09-24 08:12:05.358000\n",
    "1:0;0;0;20.799999237060547;299;0;0;0;0;0;0;0;0;0;0;2019-09-24 08:12:06.015000;2019-09-24 08:12:06.015000\n",
    "2:0;0;0;20.799999237060547;400;0;0;0;0;0;0;0;0;0;0;2019-09-24 08:12:06.983000;2019-09-24 08:12:06.983000\n",
    "3:0;0;0;20.799999237060547;501;0;0;0;0;0;0;0;0;0;0;2019-09-24 08:12:07.959000;2019-09-24 08:12:07.959000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
